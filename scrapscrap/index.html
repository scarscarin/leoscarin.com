<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>scrap, scrap... You are the web crawler!</title>

  <style>
    :root {
      --bg: #0b0f14;
      --panel: #101826;
      --text: #e6edf3;
      --muted: #9aa4b2;
      --border: rgba(255,255,255,.10);
      --shadow: 0 10px 30px rgba(0,0,0,.35);
      --radius: 16px;
    }

    * { box-sizing: border-box; }
    body {
      margin: 0;
      min-height: 100vh;
      display: grid;
      grid-template-rows: auto 1fr auto;
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial, "Apple Color Emoji", "Segoe UI Emoji";
      background: radial-gradient(1200px 600px at 20% 10%, rgba(99,102,241,.15), transparent 60%),
                  radial-gradient(900px 500px at 90% 30%, rgba(34,197,94,.10), transparent 55%),
                  var(--bg);
      color: var(--text);
    }

    header {
      padding: 28px 18px 12px;
      display: grid;
      place-items: center;
      text-align: center;
    }
    h1 {
      margin: 0;
      font-size: clamp(1.4rem, 3vw, 2.2rem);
      letter-spacing: .2px;
    }
    .sub {
      margin-top: 8px;
      color: var(--muted);
      font-size: .95rem;
    }

    main {
      padding: 16px 18px 28px;
      display: grid;
      place-items: center;
    }

    .card {
      width: min(980px, 100%);
      background: linear-gradient(180deg, rgba(255,255,255,.04), rgba(255,255,255,.02));
      border: 1px solid var(--border);
      box-shadow: var(--shadow);
      border-radius: var(--radius);
      overflow: hidden;
    }

    .toolbar {
      display: flex;
      align-items: center;
      justify-content: space-between;
      gap: 12px;
      padding: 12px 14px;
      border-bottom: 1px solid var(--border);
      background: rgba(16, 24, 38, .55);
      backdrop-filter: blur(6px);
    }

    .lang {
      display: inline-flex;
      align-items: center;
      gap: 10px;
      color: var(--muted);
      font-size: .92rem;
    }
    .pill {
      font-size: .78rem;
      padding: 4px 10px;
      border-radius: 999px;
      border: 1px solid var(--border);
      color: var(--text);
      background: rgba(255,255,255,.05);
    }

    button {
      border: 1px solid var(--border);
      background: rgba(255,255,255,.06);
      color: var(--text);
      border-radius: 10px;
      padding: 8px 12px;
      font-weight: 600;
      cursor: pointer;
      transition: transform .05s ease, background .15s ease;
      user-select: none;
    }
    button:hover { background: rgba(255,255,255,.10); }
    button:active { transform: translateY(1px); }

    pre {
      margin: 0;
      padding: 16px 16px 18px;
      overflow: auto;
      background: rgba(5, 10, 18, .55);
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size: 0.95rem;
      line-height: 1.5;
      tab-size: 2;
    }
    code { display: block; white-space: pre; }

    /* Simple “Python-ish” highlighting */
    .tok-comment { color: #7b8aa5; font-style: italic; }
    .tok-string  { color: #f2cc60; }
    .tok-number  { color: #a5d6ff; }
    .tok-kw      { color: #c792ea; font-weight: 650; }
    .tok-fn      { color: #82d2ce; }
    .tok-builtin { color: #8bd5ff; }
    .tok-op      { color: #b6c2d9; }

    footer {
      padding: 14px 18px 22px;
      text-align: center;
      color: var(--muted);
      font-size: .92rem;
    }
    a { color: inherit; }
  </style>
</head>

<body>
  <header>
    <h1>scrap, scrap... You are the web crawler!</h1>
    <div class="sub">Paste your Python later — this block already supports simple color highlighting.</div>
  </header>

  <main>
    <section class="card" aria-label="Python code card">
      <div class="toolbar">
        <div class="lang">
          <span class="pill">python</span>
          <span id="copyStatus" aria-live="polite"></span>
        </div>
        <button id="copyBtn" type="button">Copy</button>
      </div>

      <!-- Raw code lives here (copy reads from this) -->
      <pre aria-label="Python code"><code id="rawCode">
# LET'S START DIGGING
# use the requests library to request a copy of the HTML document
import requests

website = "http://mouchette.org/"

r = requests.get(website)
print(r.text)

# COLLECT DIRT IN THE BUCKET
# download the page into a dump folder using the os library
import os

with open("dump/index.html", "w") as f:
    f.write(r.text)

# WE GOT SOMETHING
# use the bs4 library to find only the elements containing href and src

from bs4 import BeautifulSoup

soup = BeautifulSoup(r.text, "html.parser")

hrefs = [tag["href"] for tag in soup.find_all(href=True)]
print("hrefs", hrefs)

srcs  = [tag["src"]  for tag in soup.find_all(src=True)]
print("srcs:", srcs)
    
# CLEAN IT UP FROM THE DIRT
# we can remove duplicate links by creating a list with all the href and src
links = hrefs + srcs
links = list(dict.fromkeys(links))
print("unique links:", links)

# RINSE IT WITH WATER
# let's filter only pages that are HTML and place the media aside
pages = [p for p in links if ".html" in p or ".php" in p]
print(pages)

media = [m for m in links if ".jpg" in m or ".gif" in m]
print(media)

# LABEL IT
# let's transform the text into links (we add the "/name_of_page.html" to "mouchette.org")

from urllib.parse import urljoin
from pathvalidate import sanitize_filepath

urls = pages + media
urls = [urljoin(website, u) for u in urls]
print(urls)

# BRING IT HOME
# let's download the content we found inside the dump folder

for u in urls:
    data = requests.get(u).content
    
    u = u.replace(website, "")
    
    path = "dump/" + u
    path = sanitize_filepath("dump/" + u)
    
    os.makedirs(os.path.dirname(path), exist_ok=True)
        
    with open(path, "wb") as f:
        f.write(data)
        
        print(u)

# DIG DEEPER
# repeat the process for all discovered HTML pages

# visited = set()
queue = [website]

while queue:

    url = queue.pop(0)

    print("DIGGING:", url)

    r = requests.get(url)
    content = r.text

    soup = BeautifulSoup(content, "html.parser")

    hrefs = [tag["href"] for tag in soup.find_all(href=True)]
    srcs  = [tag["src"]  for tag in soup.find_all(src=True)]
    links = list(dict.fromkeys(hrefs + srcs))

    # separate pages and media
    pages = [l for l in links if ".html" in l or ".php" in l]
    media = [l for l in links if ".jpg" in l or ".gif" in l]

    # make absolute
    pages = [urljoin(url, p) for p in pages]
    media = [urljoin(url, m) for m in media]
    
    from urllib.parse import urlparse

    # download media
    for m in media:
        data = requests.get(m).content
        path = urlparse(m).path.lstrip("/")
        local = "dump/" + path

        os.makedirs(os.path.dirname(local), exist_ok=True)

        with open(local, "wb") as f:
            f.write(data)
            print("downloaded:", path)

    # queue new pages
    for p in pages:
        if "mouchette.org" in p:
            queue.append(p)
            




</code></pre>
    </section>
  </main>

  <footer>
    made by Leo Scarin for The Hamm's event on Automated Archiving
  </footer>

  <script>
    // --- Simple Python syntax highlighter (regex-based, lightweight) ---
    // NOTE: This is not a full parser; it's meant to look good for workshop/demo code.
    const PY_KEYWORDS = new Set([
      "False","None","True","and","as","assert","async","await","break","class","continue",
      "def","del","elif","else","except","finally","for","from","global","if","import","in",
      "is","lambda","nonlocal","not","or","pass","raise","return","try","while","with","yield"
    ]);

    const PY_BUILTINS = new Set([
      "print","len","range","list","dict","set","tuple","int","float","str","bool","type",
      "enumerate","zip","map","filter","sorted","sum","min","max","any","all","open"
    ]);

    function escapeHtml(s) {
      return s.replace(/&/g,"&amp;").replace(/</g,"&lt;").replace(/>/g,"&gt;");
    }

    function highlightPython(raw) {
      // Work on an escaped string so we can safely inject spans.
      let s = escapeHtml(raw);

      // Strings (single, double, triple-ish)
      // First mark strings to avoid keyword matches inside them.
      // We’ll do a pragmatic approach: replace strings with tokens then reinsert.
      const store = [];
      const put = (match) => {
        const key = `___STR${store.length}___`;
        store.push(match);
        return key;
      };

      s = s.replace(/("""[\s\S]*?"""|'''[\s\S]*?'''|"(?:\\.|[^"\\])*"|'(?:\\.|[^'\\])*')/g, put);

      // Comments (# ...)
      s = s.replace(/(^|[^\\])(#.*$)/gm, (m, p1, p2) => `${p1}<span class="tok-comment">${p2}</span>`);

      // Numbers
      s = s.replace(/\b(\d+(\.\d+)?|\.\d+)\b/g, '<span class="tok-number">$1</span>');

      // Operators / punctuation (light touch)
      s = s.replace(/([=+\-*/%<>!]=?|[(){}\[\],.:])/g, '<span class="tok-op">$1</span>');

      // Function defs: def name(
      s = s.replace(/\bdef\s+([A-Za-z_]\w*)\s*(\()/g, (m, name, paren) =>
        `def <span class="tok-fn">${name}</span>${paren}`
      );

      // Keywords
      s = s.replace(/\b([A-Za-z_]\w*)\b/g, (m, w) => {
        if (PY_KEYWORDS.has(w)) return `<span class="tok-kw">${w}</span>`;
        if (PY_BUILTINS.has(w)) return `<span class="tok-builtin">${w}</span>`;
        return w;
      });

      // Reinsert strings
      for (let i = 0; i < store.length; i++) {
        const key = `___STR${i}___`;
        const safe = `<span class="tok-string">${escapeHtml(store[i])}</span>`;
        s = s.replaceAll(key, safe);
      }
      return s;
    }

    const rawCodeEl = document.getElementById("rawCode");
    const copyBtn = document.getElementById("copyBtn");
    const copyStatus = document.getElementById("copyStatus");

    function renderHighlighted() {
      const raw = rawCodeEl.textContent;
      rawCodeEl.innerHTML = highlightPython(raw);
    }

    // Copy button copies RAW text, not highlighted HTML
    copyBtn.addEventListener("click", async () => {
      const raw = rawCodeEl.textContent; // textContent returns plain text even after highlighting
      try {
        await navigator.clipboard.writeText(raw);
        copyStatus.textContent = "Copied ✓";
        setTimeout(() => (copyStatus.textContent = ""), 1200);
      } catch (e) {
        // Fallback for older browsers
        const ta = document.createElement("textarea");
        ta.value = raw;
        document.body.appendChild(ta);
        ta.select();
        document.execCommand("copy");
        document.body.removeChild(ta);
        copyStatus.textContent = "Copied ✓";
        setTimeout(() => (copyStatus.textContent = ""), 1200);
      }
    });

    // Initial highlight
    renderHighlighted();

    // Optional: if you later make the code editable, call renderHighlighted() after edits.
  </script>
</body>
</html>
