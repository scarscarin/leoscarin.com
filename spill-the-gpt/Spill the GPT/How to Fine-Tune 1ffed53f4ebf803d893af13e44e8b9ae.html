<html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><title>How to Fine-Tune</title><style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 10px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
	margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.callout img.notion-static-icon {
	width: 1em;
	height: 1em;
}

.callout p {
	margin: 0;
}

.callout h1,
.callout h2,
.callout h3 {
	margin: 0 0 0.6rem;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

blockquote.quote-large {
	font-size: 1.25em;
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray {
	color: rgba(125, 122, 117, 1);
	fill: rgba(125, 122, 117, 1);
}
.highlight-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.highlight-orange {
	color: rgba(210, 123, 45, 1);
	fill: rgba(210, 123, 45, 1);
}
.highlight-yellow {
	color: rgba(203, 148, 52, 1);
	fill: rgba(203, 148, 52, 1);
}
.highlight-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.highlight-blue {
	color: rgba(56, 125, 201, 1);
	fill: rgba(56, 125, 201, 1);
}
.highlight-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(207, 81, 72, 1);
	fill: rgba(207, 81, 72, 1);
}
.highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.highlight-gray_background {
	background: rgba(42, 28, 0, 0.07);
}
.highlight-brown_background {
	background: rgba(139, 46, 0, 0.086);
}
.highlight-orange_background {
	background: rgba(224, 101, 1, 0.129);
}
.highlight-yellow_background {
	background: rgba(211, 168, 0, 0.137);
}
.highlight-teal_background {
	background: rgba(0, 100, 45, 0.09);
}
.highlight-blue_background {
	background: rgba(0, 124, 215, 0.094);
}
.highlight-purple_background {
	background: rgba(102, 0, 178, 0.078);
}
.highlight-pink_background {
	background: rgba(197, 0, 93, 0.086);
}
.highlight-red_background {
	background: rgba(223, 22, 0, 0.094);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(125, 122, 117, 1);
	fill: rgba(125, 122, 117, 1);
}
.block-color-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.block-color-orange {
	color: rgba(210, 123, 45, 1);
	fill: rgba(210, 123, 45, 1);
}
.block-color-yellow {
	color: rgba(203, 148, 52, 1);
	fill: rgba(203, 148, 52, 1);
}
.block-color-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.block-color-blue {
	color: rgba(56, 125, 201, 1);
	fill: rgba(56, 125, 201, 1);
}
.block-color-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(207, 81, 72, 1);
	fill: rgba(207, 81, 72, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.block-color-blue_background {
	background: rgba(229, 242, 252, 1);
}
.block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.select-value-color-blue { background-color: rgba(0, 118, 217, 0.203); }
.select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style></head><body><article id="1ffed53f-4ebf-803d-893a-f13e44e8b9ae" class="page sans"><header><div class="page-header-icon undefined"><span class="icon">‚ùì</span></div><h1 class="page-title">How to Fine-Tune</h1><p class="page-description"></p></header><div class="page-body"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="20ced53f-4ebf-8084-9e2f-e5c0408c64a6"><div style="font-size:1.5em"><span class="icon">‚ùî</span></div><div style="width:100%"><p id="20aed53f-4ebf-8064-ad45-e97864d4fa5d" class=""><strong>What is Fine-Tuning?</strong></p><p id="20aed53f-4ebf-807f-baba-c7739d8e6100" class="">Fine-tuning means taking a pre-trained language model‚Äîsomething that already learned English from millions of examples‚Äîand training it further to match a particular writing style you choose. </p><p id="20ced53f-4ebf-808a-a978-f36446a221e0" class="">You can do this with just about 100 examples. If you haven‚Äôt, see <a href="How%20to%20Prepare%20your%20Dataset%20205ed53f4ebf803188ebfd72c1c2a4b4.html"><span class="icon">‚ùì</span>How to Prepare your Dataset</a> </p></div></figure><h1 id="205ed53f-4ebf-80ba-b631-e2983009b1ef" class="">Getting Started</h1><p id="205ed53f-4ebf-80bd-8b77-e659de3d5a75" class="">The first step to fine-tune a language model‚Ä¶ is finding a language model!</p><p id="20aed53f-4ebf-806e-9a6a-cf4e6aa967f2" class="">We&#x27;ll use <a href="https://huggingface.co/distilbert/distilgpt2">DistilGPT2</a>, a simplified and smaller version of GPT-2: the popular language model developed by OpenAI in 2019.</p><div id="20aed53f-4ebf-808c-a52e-ce035fb3e44e" class="column-list"><div id="20aed53f-4ebf-80db-9d82-df5055135826" style="width:50%" class="column"><p id="20aed53f-4ebf-8035-87f5-de9d589c866a" class="">DistilGPT2 is a <a href="https://huggingface.co/models?pipeline_tag=text-generation">Text Generation Model</a>, which you can find on <a href="https://huggingface.co/">ü§ó HuggingFace</a>: an online platform hosting models and datasets.</p><p id="20aed53f-4ebf-80dc-84a8-d1dacde53e2f" class="">You can tell it&#x27;s small by looking at the size of its <code>.safetensors</code> file [see image].</p><p id="20aed53f-4ebf-80a9-b42a-f449002618b0" class="">To fine-tune DistilGPT2, you&#x27;ll use Python (a programming language) and a few specialized tools available through <a href="https://colab.research.google.com/">Google Colab</a>, Google&#x27;s online coding platform.<br/></p></div><div id="20aed53f-4ebf-80f3-a547-e91d1933f00f" style="width:49.99999999999999%" class="column"><figure id="205ed53f-4ebf-801f-ba64-e2e20126243f" class="image"><a href="How%20to%20Fine-Tune/image.png"><img style="width:332px" src="How%20to%20Fine-Tune/image.png"/></a></figure></div></div><p id="20aed53f-4ebf-80f8-8795-d33d3431a36e" class="">If you don&#x27;t have an account yet, create one on Google Colab.</p><p id="1ffed53f-4ebf-80c3-941f-ce8aeafeda90" class="">Make sure your dataset (text you wrote or collected) is ready. If you haven&#x27;t prepared it yet, check out <a href="How%20to%20Prepare%20your%20Dataset%20205ed53f4ebf803188ebfd72c1c2a4b4.html"><span class="icon">‚ùì</span>How to Prepare your Dataset</a> </p><h2 id="205ed53f-4ebf-804a-b87a-ded9ad8ed605" class="">Open the code in Google Colab</h2><p id="205ed53f-4ebf-80ce-9c2b-ca5091e862a9" class="">Here‚Äôs the full notebook code you‚Äôll use:</p><figure id="20aed53f-4ebf-80bb-9f70-d069938803fd"><a href="https://colab.research.google.com/drive/1uvr_fEyJvihbeZB-E_dI9UQPPN7T-RM9?usp=sharing" class="bookmark source"><div class="bookmark-info"><div class="bookmark-text"><div class="bookmark-title">Google Colab</div></div><div class="bookmark-href"><img src="https://ssl.gstatic.com/colaboratory-static/common/9519e4c87b9910d026f54a0b2e16eaae/img/favicon.ico" class="icon bookmark-icon"/>https://colab.research.google.com/drive/1uvr_fEyJvihbeZB-E_dI9UQPPN7T-RM9?usp=sharing</div></div><img src="https://colab.research.google.com/img/colab_favicon_256px.png" class="bookmark-image"/></a></figure><p id="205ed53f-4ebf-8067-b667-e23b6611c844" class="">If you know Google Colab already, run the code directly. Otherwise, follow the steps below carefully.</p><h2 id="205ed53f-4ebf-801d-a4d2-e6f13eee1cdf" class="">Make a copy in your Drive</h2><div id="20aed53f-4ebf-8038-b408-e6d5fe71900e" class="column-list"><div id="20aed53f-4ebf-80f4-951d-ddfc32f55ef6" style="width:50%" class="column"><p id="20aed53f-4ebf-80d5-baf3-c7515c0b8e83" class="">After opening our <a href="https://colab.research.google.com/drive/1jSZfqayViVxL-aGj3dKwfRF3fqL7ZBAZ">code notebook on Google Colab</a>, you‚Äôll see &quot;cells&quot; of text and code.</p><p id="20aed53f-4ebf-80be-a140-d559c0b12c8e" class="">You can&#x27;t edit this notebook directly because it&#x27;s shared from my account. First, click <code>File ‚Üí Save a copy in Drive</code>. This opens your own editable copy.</p><p id="20aed53f-4ebf-801d-86e2-c687662ab80e" class="">
</p></div><div id="20aed53f-4ebf-8027-91f3-faa0cc9adc13" style="width:50%" class="column"><figure id="205ed53f-4ebf-800b-847d-ca385dc5fb8c" class="image"><a href="How%20to%20Fine-Tune/15502c32-e29d-459b-bbb4-89e53538bf90.png"><img style="width:320px" src="How%20to%20Fine-Tune/15502c32-e29d-459b-bbb4-89e53538bf90.png"/></a></figure></div></div><h1 id="205ed53f-4ebf-80df-aab3-c8f69491da0a" class="">ü•ó Prepare the Project</h1><p id="205ed53f-4ebf-80e6-b574-f5fb0089cd25" class=""><br/>Run each code-cell by clicking the <strong>PLAY</strong> button.</p><figure id="205ed53f-4ebf-805b-a7ac-e4929dfb5b8f" class="image"><a href="How%20to%20Fine-Tune/image%201.png"><img style="width:455px" src="How%20to%20Fine-Tune/image%201.png"/></a></figure><h2 id="1ffed53f-4ebf-8025-8e55-c4c3430c4e8b" class="">Install Packages</h2><p id="205ed53f-4ebf-8048-92b9-eae3374a55ab" class="">First, install Python packages (tools):</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="1ffed53f-4ebf-80f5-a1bd-d022b0debc31" class="code code-wrap"><code class="language-Shell" style="white-space:pre-wrap;word-break:break-all">!pip install -U transformers[torch] tf-keras datasets</code></pre><p id="20aed53f-4ebf-8056-900b-f87fceb05d52" class="">This installs:</p><ul id="20aed53f-4ebf-8051-8205-d6265769ce67" class="bulleted-list"><li style="list-style-type:disc"><a href="https://pypi.org/project/transformers/">transformers</a> (for language models)</li></ul><ul id="20aed53f-4ebf-809e-a499-e2f135ac4212" class="bulleted-list"><li style="list-style-type:disc"><a href="https://pypi.org/project/torch/">torch</a> (helps models learn)</li></ul><ul id="20aed53f-4ebf-80cd-9420-cbb113a396d5" class="bulleted-list"><li style="list-style-type:disc"><a href="https://pypi.org/project/tf-keras/">tf-keras</a> (extra tools for AI)</li></ul><ul id="20aed53f-4ebf-807e-ba3d-ff95afdfe1b2" class="bulleted-list"><li style="list-style-type:disc"><a href="https://pypi.org/project/datasets/">datasets</a> (manages your text data)</li></ul><p id="20aed53f-4ebf-80a1-a23b-f15647b0c7cd" class="">
</p><p id="205ed53f-4ebf-8010-bf4b-cb91cb8f2f3a" class=""><strong>‚åõ Time</strong>: 5-6 minutes ‚Äî time to download packages</p><hr id="205ed53f-4ebf-801f-8dbc-f98f32aea821"/><h2 id="205ed53f-4ebf-80c4-b547-e640e1624fd2" class="">Import Libraries</h2><p id="205ed53f-4ebf-80cc-970b-cc74abbf6c23" class="">From the packages we installed, we need to import a few libraries.</p><ul id="20aed53f-4ebf-80e8-81a1-c07aa874915d" class="bulleted-list"><li style="list-style-type:disc"><code>files</code> lets you upload your text.</li></ul><ul id="20aed53f-4ebf-80c6-90e6-d85c9673649a" class="bulleted-list"><li style="list-style-type:disc"><code>load_dataset</code> helps Python read your text.</li></ul><ul id="20aed53f-4ebf-8068-b476-c26844663048" class="bulleted-list"><li style="list-style-type:disc"><code>transformers</code> tools help the model learn from your text.</li></ul><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-80f8-b54b-cdb90d79fc30" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">from google.colab import files
from datasets import load_dataset
from transformers import (¬† ¬† 
	AutoTokenizer,¬† ¬† 
	AutoModelForCausalLM,¬† ¬† 
	DataCollatorForLanguageModeling,¬† ¬† 
	Trainer,¬† ¬† 
	TrainingArguments,
	)</code></pre><p id="205ed53f-4ebf-8056-bd60-d22ad1486ca5" class=""><strong>‚åõ Time</strong>: 1 minute</p><hr id="205ed53f-4ebf-80d3-8783-f1b47be9fb7e"/><h2 id="205ed53f-4ebf-8017-9eca-f96ba0283018" class="">Upload your Gossip</h2><p id="20aed53f-4ebf-801a-98b7-dfe6e95d4b6d" class="">Upload your text file (<code>.txt</code>) containing your sentences:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-80ce-be14-c6df346d0076" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">uploaded = files.upload() ¬†
filename = list(uploaded.keys())[0]</code></pre><div id="205ed53f-4ebf-80f9-8845-c1c645f15ce9" class="column-list"><div id="205ed53f-4ebf-806e-bc60-f8c1d6c5f270" style="width:50%" class="column"><p id="20aed53f-4ebf-8042-b57b-f031f73bb22a" class="">Click <strong>Browse‚Ä¶</strong>, select your file, and confirm it&#x27;s uploaded on the left üìÅ icon.</p><p id="20aed53f-4ebf-8024-9350-efca62f41f0c" class=""><em>Note ‚Üí Your file must be </em><em><code>.txt</code></em><em>.</em></p></div><div id="205ed53f-4ebf-80c0-b706-fa4a982de114" style="width:50%" class="column"><figure id="205ed53f-4ebf-8056-bdec-f95c647fc769" class="image"><a href="How%20to%20Fine-Tune/image%202.png"><img style="width:710px" src="How%20to%20Fine-Tune/image%202.png"/></a></figure></div></div><hr id="205ed53f-4ebf-801f-a46d-de6a04de357a"/><h1 id="205ed53f-4ebf-8084-96b7-f4385361ca50" class="">ü•∏ Format your Dataset</h1><h2 id="205ed53f-4ebf-8020-a3f2-e117b96eca92" class="">Convert the Gossip file into a Training Dataset</h2><p id="20aed53f-4ebf-80fb-ac8e-d1b8e8abcf5e" class="">Tell Python your file is your training data:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-80cc-a5ca-c60515365704" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">data_files = {&quot;train&quot;: filename}
ds = load_dataset(&quot;text&quot;, data_files=data_files)</code></pre><p id="205ed53f-4ebf-80f0-9e27-f74c073c332b" class="">‚åõ <strong>Time</strong>: immediate</p><hr id="205ed53f-4ebf-8068-8102-fe6d3b758cdc"/><h2 id="205ed53f-4ebf-8046-a2b9-efd60198c973" class="">Download Tokenizer and Model</h2><p id="205ed53f-4ebf-8023-982f-f0352e52bdd0" class="">Our dataset of words won‚Äôt do much. We need to convert it into numbers through a process called <em>tokenization</em>. This process converts words like <code>I heard that</code>  into numbers like  <code>40, 1045, 1115</code>, which the model can understand.</p><p id="205ed53f-4ebf-80af-b703-de5cb24c1503" class=""><strong>DistilGPT2</strong> has a built-in tokenizer. We can download it using <code>AutoTokenizer.from_pretrained()</code> </p><div id="205ed53f-4ebf-80ba-9f72-c2e1e11b6cab" class="column-list"><div id="205ed53f-4ebf-80e4-8f9b-d9d27a4c2be2" style="width:50%" class="column"><p id="205ed53f-4ebf-800e-a7b9-ec1ac5ebf83a" class="">After loading the tokenizer, we load <strong>DistilGPT2 </strong>with <code>AutoModelForCausalLM.from_pretrained()</code>.</p><p id="205ed53f-4ebf-80d7-a5d6-cd2a8a95bef3" class=""><em>Note ‚Üí Models bigger than DistilGPT2 will download slower.</em></p></div><div id="205ed53f-4ebf-802d-b1c3-ef4709f43f2f" style="width:49.99999999999999%" class="column"><figure id="205ed53f-4ebf-807d-9898-cfcda76f830d" class="image"><a href="How%20to%20Fine-Tune/image%203.png"><img style="width:710px" src="How%20to%20Fine-Tune/image%203.png"/></a></figure></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-8091-8ec8-f664fa5a5668" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">tokenizer = AutoTokenizer.from_pretrained(&quot;distilgpt2&quot;)
tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(&quot;distilgpt2&quot;)
model.config.pad_token_id = model.config.eos_token_id</code></pre><p id="205ed53f-4ebf-8077-a92d-f5c8bcc5cb9c" class=""><strong>‚åõ Time</strong>: &lt; 1 minute ‚Äî depends on download time</p><hr id="205ed53f-4ebf-80a0-b980-cb39e19a9696"/><h2 id="205ed53f-4ebf-80c7-b11d-fa4eb8181ae4" class="">Tokenize your Dataset</h2><p id="205ed53f-4ebf-8004-bb12-fbe5a6d44dd8" class="">Convert text to numbers (tokens). You tokenize your dataset into smaller groups (batches) of words (tokens), so the model learns effectively without overwhelming the computer.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-8056-8e63-f130075d7e90" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">def tokenize_batch(batch):
    return tokenizer(
        batch[&quot;text&quot;],
        truncation=True,
        max_length=64,
        padding=&quot;max_length&quot;,
    )
    
tokenized = ds[&quot;train&quot;].map(tokenize_batch, batched=True, remove_columns=[&quot;text&quot;])</code></pre><p id="205ed53f-4ebf-808a-89de-d18489c75f4d" class="">‚åõ <strong>Time</strong>: few seconds ‚Äî depends on batch and dataset size</p><hr id="205ed53f-4ebf-8051-abe0-ce09f30cbfce"/><h2 id="205ed53f-4ebf-80c2-a358-e1a3cf916cc8" class="">Create the Data Collator</h2><p id="205ed53f-4ebf-80c9-be80-eb649ec5e581" class="">To tidy up our dataset, we do a process called <em>padding</em>, which adds [blank] spaces to sentences that are shorter than the rest.</p><blockquote id="205ed53f-4ebf-80ea-b740-c6578ef37700" class=""><mark class="highlight-default"><code>&quot;she failed exams&quot;</code></mark><mark class="highlight-default"> ‚Üí </mark><mark class="highlight-default"><code>&quot;she failed exams [blank] [blank] [blank] [blank] [blank]&quot;</code></mark></blockquote><blockquote id="205ed53f-4ebf-8094-8cb3-c56ccbfdf848" class=""><mark class="highlight-default"><code>&quot;yesterday I saw my neighbor kissing someone new&quot;</code></mark> ‚Üí stays as-is</blockquote><p id="205ed53f-4ebf-80c8-bd80-f6347133ccbb" class="">We do this now, with a <em>Data Collator</em>: a function that takes a bunch of sentences, makes sure they are all the same size (by padding short ones), puts them together into a batch, and prepares them for the model.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-807d-a623-ee13f5b9bb86" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)</code></pre><p id="205ed53f-4ebf-80b3-9e50-d7f60ef7e5ce" class="">‚åõ <strong>Time</strong>: immediate</p><hr id="205ed53f-4ebf-8089-bfbb-d4e9477b2485"/><h1 id="205ed53f-4ebf-80df-9f51-c5f341beada0" class="">üç∞ Prepare the Training</h1><h2 id="205ed53f-4ebf-8043-928d-f9bc236b5db9" class="">Indicate Training Instructions</h2><p id="205ed53f-4ebf-80dd-9034-d8a0e2fc3bed" class="">Give the training process instructions.</p><p id="205ed53f-4ebf-8010-9d0c-d8c25904953b" class="">We are going to try a ‚Äúfast but soft‚Äù example for this exercise (on the left).</p><p id="20aed53f-4ebf-804e-a074-d97202e913b9" class="">For the real training, use the ‚Äúslow but strong‚Äù example (on the right).</p><div id="205ed53f-4ebf-80e2-b981-c15544b98047" class="column-list"><div id="205ed53f-4ebf-8096-b527-d96f9860ff85" style="width:50%" class="column"><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-803f-8621-e6672f69b839" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">training_args = TrainingArguments(
    output_dir=&quot;./distilgpt2-finetuned&quot;,
    overwrite_output_dir=True,
    num_train_epochs=3,              
    per_device_train_batch_size=8,    
    learning_rate=1e-5,
    weight_decay=0.01,
    logging_steps=10,
    save_steps=100,
    save_total_limit=2,
    fp16=True,
    report_to=[&quot;none&quot;]                        
)


</code></pre></div><div id="205ed53f-4ebf-8019-95b7-d2463c663aba" style="width:49.99999999999999%" class="column"><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-80ab-b9e1-d29c0cc79cca" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">training_args = TrainingArguments(
    output_dir=&quot;./distilgpt2-finetuned&quot;,
    overwrite_output_dir=True,
    num_train_epochs=500,              
    per_device_train_batch_size=8,
    learning_rate=1e-6,
    weight_decay=0.01,
    logging_steps=20,
    save_steps=100,
    save_total_limit=2,
    fp16=True,
    report_to=[&quot;none&quot;],            
    gradient_accumulation_steps=2,
	  warmup_steps=50,
    max_grad_norm=1.0,                
)</code></pre></div></div><p id="20aed53f-4ebf-8000-8fe1-fa1447a29cca" class="">You want to look at two instructions, in particular:</p><h3 id="20aed53f-4ebf-802b-a25c-cbe0998029e5" class="">Number of Epochs</h3><blockquote id="20aed53f-4ebf-80ef-a6cd-c989f1834d87" class=""><mark class="highlight-default"><code>num_train_epochs=3</code></mark><mark class="highlight-default"> ‚Üí goes over the entire dataset 3 times. You can bring this up to 10-50 for a 100-500 lines dataset. The smaller the dataset, the more the </mark><em><mark class="highlight-default">epochs.</mark></em></blockquote><p id="20aed53f-4ebf-8067-96f4-d930af5f4574" class="">Increasing this value increases the time of training. You can start with <mark class="highlight-default"><code>3</code></mark>, see the results, then go up until it‚Äôs good enough.</p><h3 id="20aed53f-4ebf-807f-bbcd-d6a0db5d3bff" class="">Learning Rate</h3><blockquote id="20aed53f-4ebf-809f-ba5e-fef08ce1205f" class=""><mark class="highlight-default"><code>learning_rate=1e-5</code></mark><mark class="highlight-default"> ‚Üí indicates how ‚Äúaggressively‚Äù the model updates what it knows. A value too low makes the learning very slow but more precise.</mark></blockquote><p id="20aed53f-4ebf-8001-a301-d374f9d54761" class="">You can try <mark class="highlight-default"><code>5e-5</code></mark><mark class="highlight-default"> or </mark><mark class="highlight-default"><code>2e-5</code></mark><mark class="highlight-default"> if you want faster learning at first.</mark></p><p id="205ed53f-4ebf-801c-9c47-f1817df249cf" class=""><mark class="highlight-default"><mark class="highlight-default_background">Note ‚Üí Google Colab‚Äôs free tier limits your usage to approx. 3h30m.</mark></mark></p><p id="20aed53f-4ebf-8027-b149-f2f69bbd1e46" class="">
</p><p id="20aed53f-4ebf-801f-a443-f61b277e5e0f" class="">‚åõ <strong>Time:</strong> immediate ‚Äî we are just giving instructions. Not training, yet.</p><hr id="20aed53f-4ebf-80ae-89fd-c758a2fdbafa"/><h2 id="205ed53f-4ebf-80c9-87f2-e6a155fee856" class="">Feed the Instructions to the Trainer</h2><p id="205ed53f-4ebf-8028-a302-cc958e36ab5b" class="">Hand everything (model, instructions, dataset) to the trainer:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-8006-b3cb-d703c876d23f" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized,
    data_collator=data_collator,
)</code></pre><p id="205ed53f-4ebf-80ae-ac1d-cfb89dbde00c" class="">‚åõ <strong>Time</strong>: immediate</p><hr id="205ed53f-4ebf-8049-8454-c9c2d557d962"/><h1 id="205ed53f-4ebf-80cb-b0d1-e28fca0651a6" class="">üèÉ‚Äç‚ôÇÔ∏èTrain!</h1><h2 id="205ed53f-4ebf-801c-a9c2-d3136c1e1d8d" class="">Run Trainer and Save Model</h2><p id="205ed53f-4ebf-8003-8fd2-e15100aff5ec" class="">That‚Äôs it! Now sit back, start training and save your fine-tuned model:</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-80b8-ba66-d52bee0e2820" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">trainer.train()

trainer.save_model()</code></pre><p id="205ed53f-4ebf-8038-8064-f53ec205e2de" class="">‚åõ <strong>Time</strong>: variable ‚Äî depends on training arguments (15 minutes to 3 hours)</p><p id="205ed53f-4ebf-8004-be7f-f4bd717eeb5c" class="">
</p><div id="205ed53f-4ebf-8036-8970-f496272d27c3" class="column-list"><div id="205ed53f-4ebf-8069-a2e0-fd656177ea11" style="width:50%" class="column"><p id="205ed53f-4ebf-80dd-81c0-eed77e2e5852" class="">While you train, you can visualise the progress by looking at the <em>steps</em>. The amount of steps depends on both the amount of <em>epochs </em>and the size of <em>batches</em>.</p><p id="205ed53f-4ebf-805f-8fd6-e46dcebe7b57" class="">Every 10 steps, you can see the <em>Training Loss</em>: the smaller this is the more accurately your model is learning.</p><p id="205ed53f-4ebf-80d7-8634-f081442bed41" class="">
</p></div><div id="205ed53f-4ebf-80e8-a1ec-cd3df7d5a0c3" style="width:50%" class="column"><figure id="205ed53f-4ebf-803d-8564-f2c73d295c18" class="image"><a href="How%20to%20Fine-Tune/image%204.png"><img style="width:332px" src="How%20to%20Fine-Tune/image%204.png"/></a></figure></div></div><h2 id="205ed53f-4ebf-80a6-a27a-ca3133313e65" class="">Prepare the Model for Download</h2><p id="205ed53f-4ebf-80aa-9475-f814bf1d0d0d" class="">Once saved, you can see your model‚Äôs folder on the side, by clicking on the üìÅ icon:</p><figure id="205ed53f-4ebf-802f-9e93-e855b35c115b" class="image"><a href="How%20to%20Fine-Tune/image%205.png"><img style="width:304px" src="How%20to%20Fine-Tune/image%205.png"/></a></figure><p id="205ed53f-4ebf-80b3-b2e8-d1e3f7adddfd" class="">In order to download it, you need to run a command that ‚Äúzips‚Äù the folder into one file.</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-803b-94a8-ebe43d6fef95" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">!zip -r distilgpt2-finetuned.zip distilgpt2-finetuned</code></pre><p id="205ed53f-4ebf-803d-9b95-fd4eb3e3b567" class="">‚åõ <strong>Time</strong>: 2-3 minutes</p><hr id="205ed53f-4ebf-8052-84b5-c7063815882e"/><h2 id="205ed53f-4ebf-80c6-9a14-e6641277b3a6" class="">Download the Model</h2><p id="205ed53f-4ebf-8079-902c-fdaa5264459a" class="">Finally, download the model!</p><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/><pre id="205ed53f-4ebf-8016-84ca-d4abf0d4e7d3" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">files.download(&quot;distilgpt2-finetuned.zip&quot;)</code></pre><p id="205ed53f-4ebf-80d2-823b-ec64b2dfcc18" class="">This will execute quickly, but the actual download will take a lot longer. You can check the progress under the code-cell.</p><figure id="205ed53f-4ebf-80df-a87a-e44c6a8d6aab" class="image"><a href="How%20to%20Fine-Tune/image%206.png"><img style="width:432px" src="How%20to%20Fine-Tune/image%206.png"/></a></figure><p id="205ed53f-4ebf-804b-a24e-cd39b902a0b8" class="">
</p><p id="205ed53f-4ebf-8085-8404-fb0ec8a92304" class="">Once the bar is loaded fully, make sure you accept the download in your browser.</p><figure id="205ed53f-4ebf-805b-9f2b-ddb1ccc8df90" class="image"><a href="How%20to%20Fine-Tune/image%207.png"><img style="width:432px" src="How%20to%20Fine-Tune/image%207.png"/></a></figure><p id="205ed53f-4ebf-8037-9379-eacc849f824a" class=""><strong>‚åõ Time</strong>: 15-20 minutes ‚Äî depends on file size</p><hr id="205ed53f-4ebf-8069-84a2-c705c3328db7"/><p id="20aed53f-4ebf-8076-8916-d6098fc27070" class="">Now that you have a model, let‚Äôs infer it! <a href="How%20to%20Infer%201ffed53f4ebf80a0a30cce839200c4f0.html"><span class="icon">‚ùì</span>How to Infer</a> </p></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span></body></html>